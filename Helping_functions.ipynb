{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Helping_functions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhCMLDGPJXhLyXTz3VtTR3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalrk1/tensorflow_course/blob/main/Helping_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDbTSfTyQzSX"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnF6NjJY608m"
      },
      "source": [
        "##Some usefule functions script "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbheR4vo6625"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# importing helper function\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, pred_and_plot, unzip_data, walk_through_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5yF20qzP0Xv"
      },
      "source": [
        "## downloading and unzipping zip files of data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77XScW13P86j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6134800f-c595-4e01-eeca-cc3831988b1e"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
        "\n",
        "## unzip\n",
        "zip_ref = zipfile.ZipFile('pizza_steak.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-04 16:25:17--  https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.143.128, 173.194.69.128, 173.194.79.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.143.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109579078 (105M) [application/zip]\n",
            "Saving to: ‘pizza_steak.zip.1’\n",
            "\n",
            "pizza_steak.zip.1   100%[===================>] 104.50M   195MB/s    in 0.5s    \n",
            "\n",
            "2021-10-04 16:25:18 (195 MB/s) - ‘pizza_steak.zip.1’ saved [109579078/109579078]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0Jq0OtEP93W"
      },
      "source": [
        "##Files in directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p7KGDoSQGEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed964749-6663-4dc7-c9c8-2f5aecbe8860"
      },
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filename in os.walk('pizza_steak'):\n",
        "  print(f\"there are{len(dirnames)} directories and {len(filename)} images in '{dirpath}' \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are2 directories and 1 images in 'pizza_steak' \n",
            "there are2 directories and 1 images in 'pizza_steak/train' \n",
            "there are0 directories and 750 images in 'pizza_steak/train/pizza' \n",
            "there are0 directories and 750 images in 'pizza_steak/train/steak' \n",
            "there are2 directories and 1 images in 'pizza_steak/test' \n",
            "there are0 directories and 250 images in 'pizza_steak/test/pizza' \n",
            "there are0 directories and 250 images in 'pizza_steak/test/steak' \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2WhVftr8kjQ"
      },
      "source": [
        "## Baseline model for CNN Image classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qP8yjiP8q_r"
      },
      "source": [
        "model_1 = Sequential([\n",
        "    Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(10, 3, activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Flatten(),\n",
        "    Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_1.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer = Adam(),\n",
        "    metrics = ['accuracy'],\n",
        ")\n",
        "\n",
        "history_1 = model_1.fit(\n",
        "    train_data_argumented,\n",
        "    epochs = 5,\n",
        "    steps_per_epoch = len(train_data),\n",
        "    validation_data = test_data,\n",
        "    validation_steps = len(test_data),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOK3pW7B8xxf"
      },
      "source": [
        "##Function to plot loss and accuracy curves from history of model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jx40bPz86gn"
      },
      "source": [
        "\n",
        "# ploting validation and trainning curve separately\n",
        "def plot_loss_curves(history):\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss =  history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epoch = range(len(history.history['loss']))\n",
        "\n",
        "  # plot loss\n",
        "  plt.plot(epoch, loss, label='training_loss')\n",
        "  plt.plot(epoch, val_loss, label='val_loss')\n",
        "  plt.title('loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epoch, accuracy, label='training_accuracy')\n",
        "  plt.plot(epoch, val_accuracy, label='val_accuracy')\n",
        "  plt.title('accuracy')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPQR2Fak8I2F"
      },
      "source": [
        "## Data agumentation\n",
        "\n",
        "* Improve Data accuracy\n",
        "* Reduce overfitting ( get the train and validation loss curve cloer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rG-wuM48CXz"
      },
      "source": [
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=0.2,\n",
        "                                             shear_range=0.2,\n",
        "                                             zoom_range=0.2,\n",
        "                                             width_shift_range=0.2,\n",
        "                                             height_shift_range=0.2,\n",
        "                                             horizontal_flip=True)\n",
        "\n",
        "train_data_argumented = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                               target_size=(224, 224),\n",
        "                                               class_mode = 'categorical',\n",
        "                                               batch_size = 32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBjoY5AZ4UNY"
      },
      "source": [
        "###Data Agumentation using image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFufib1W4Fs7"
      },
      "source": [
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE= 32\n",
        "\n",
        "print('Training Data')\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = train_dir,\n",
        "    image_size = IMG_SIZE,\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = BATCH_SIZE,\n",
        ")\n",
        "\n",
        "print('Test Data')\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    directory = test_dir,\n",
        "    image_size = IMG_SIZE,\n",
        "    label_mode = 'categorical',\n",
        "    batch_size = BATCH_SIZE,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KU57I7Btynb"
      },
      "source": [
        "###Data Augmentation layer using sequential model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnbdKySCuAmy"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# data augmentation stage with horizontal flipping, rotation, zooms, etc....\n",
        "data_augmentation = keras.Sequential([\n",
        "    preprocessing.RandomFlip('horizontal'),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    # preprocessing.Rescaling(1./255)\n",
        "], name='data_augmentation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-jlsoqSPc2p"
      },
      "source": [
        "##Function to plot and make predictions on our images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFeTv6qPPmLV"
      },
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "\n",
        "  # loading and preparing image\n",
        "  img = load_prep_image(filename)\n",
        "\n",
        "  # predicting\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # get predicted class\n",
        "  pred_class = class_names[int(tf.round(pred))]\n",
        "\n",
        "  # ploting image\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"prediction: {pred_class}\")\n",
        "  plt.axis(False);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDSANYT3zYxI"
      },
      "source": [
        "* **Loading and preparing images for predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2l28EwumzUKs"
      },
      "source": [
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.io.decode_image(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYBotUpmQ2-P"
      },
      "source": [
        "#Feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2xNYb7ijwsm"
      },
      "source": [
        "##Setting up callbacks\n",
        "\n",
        "* Tracking experiments with **Tensor Board callBack**\n",
        "* Model checkpoint with **Model check Callback**\n",
        "* Stopping a model from training ( before it trains to long and overfits) with the **Early Stopping Callback** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hwNbUxXmdAP"
      },
      "source": [
        "###Tensorboard Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uDVIRJeQ5T-"
      },
      "source": [
        "# creating tensorflow callback\n",
        "import datetime\n",
        "\n",
        "def creat_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime(\"%d%m%Y-&H&M\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"aving Tensorboard log file to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J5nAX1Rn333"
      },
      "source": [
        "# Tensorflow Hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIJHS41P-RK7"
      },
      "source": [
        "##Creating a function to creat model from tensorflow hub link"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztDZPfsy-ZLS"
      },
      "source": [
        "def creat_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "  \n",
        "  Args:\n",
        "    model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "    num_classes (int): Number of output neurons in output layer,\n",
        "      should be equal to number of target classes, default 10.\n",
        "\n",
        "  Returns:\n",
        "    An uncompiled Keras Sequential model with model_url as feature\n",
        "    extractor layer and Dense output layer with num_classes outputs.\n",
        "  \"\"\"\n",
        "\n",
        "  # Downloading the pretrained model and saveing it as a keras layer\n",
        "  feature_exrtraction_layer = hub.KerasLayer(model_url, \n",
        "                                             trainable=False, \n",
        "                                             impute_shape=IMAGE_SHAPE + (3,),\n",
        "                                             name='feature_extraction_layer')\n",
        "  # Creating model\n",
        "  model = Sequential([\n",
        "     feature_extraction_layer,\n",
        "     Dense(num_classes, activation='softmax', name='output_layer') \n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}